---
title: ðŸ“¦ Microservices and Docker
---

# ðŸ“¦ Microservices and Docker

## Microservices

Microservices are small dedicated services that concentrate on solving one problem in a domain. The idea is to break apart your monolith (a place where all your services live) into small independent services. Let's talk about the PROs and CONs of this approach

**PROs**

- **Can be developed and deployed independently**, deploying a Monolith app can take some time. A lot of developers working in the same codebase can make for complicated merges. With microservices all of that goes away, dedicated repos for each microservice. You can spin up or redeploy your service without spinning up a large machinery. 
- **Different teams can work on different services**, it becomes so much easier to scale up your IT operation with one team per microservice.
- **Different services can be built in different programming languages**, your company no longer need to have *one* tech stack. With this degree of freedom this means that the developers you hire can use their favorite tools and programming language to build the service. 
- **Easy to scale** with an orchestrator like Kubernetes, because microservices are turning into containers it becomes really easy to scale up the number of Microservice instances that are needed to meet your user demands like a big sale or similar. Thanks to Kubernetes this is quite easy.

**CONs**

- you need to learn about containers cause that's how you usually serve up your microservices 
- orchestration becomes a problem you need to manage, you need to find a way to easily create containers, bring them up, bring the down
- talking cross services is a thing you will need to manage
- it takes a while to mentally learn to architect and *think* in microservices

## Docker

Docker helps us create containers out of our microservices. Once our microservices are being served up as container we can push them to container registry in the Cloud. Thereafter we can have our Cloud Provider instantiate an app service from our container OR we can tell an orchestrator like Kubernetes to scale up our app in *n* instances so we can serve millions of customers.

To be able to work efficiently with Docker in this workshop, we will learn the following concepts:

- **Dockerfile**, a docker file is a recipe for what you are about to build. The file contains information such as what OS to base your image on, dependencies that needs to be installed and of course information on how to copy and run your app within the container.
- **container**, a container is a runnable black box that only has the fraction the size a VM has. The reason for that is that the container talks to the host OS instead of having a full OS inside of the container.
- **image**, an image is what you get when you build an artifact from a Dockerfile. An image isn't runnable and needs to b converted to a container first
- **docker-compose**, docker-compose is a tool you use when you need to manage several containers at once. Without it, you would have to resort to adding creation, setup, teardown commands for each container, that means a lot of scripts and simply becomes hard to manage 

## What we will build

We will build two different microservices, giving us products and reviews respectively.

For each service we will take the following steps:

- **Create** a REST Service in Node.js + Express
- **Define** a Dockerfile, we need one Dockerfile for each service 
- **Containerize**, we will create an image and container respectively, using docker-compose, so we have each container up and running and reachable from a browser

### Create a REST Service in Node.js

We will create two different services
- products service, this will return a list of product
- reviews service, this will contain info on a review and link to an id for a product

**Products service**

```
mkdir products
cd products
touch app.js
```

Now run:

```
npm init -y
```

This will create a `package.json` file.
In `package.json` add the following under `scripts`:

```json
"start": "node app.js"
```
Now your app is startable by typing `npm start`.

Add the following content to `app.js`:

```js
// products/app.js
const express = require('express')
const app = express()
const port = process.env.PORT || 3000

const products = [{
  id: 1,
  name: "Avengers - endgame"
},
{
  id: 2,
  name: "Captain America"
},
{
  id: 3,
  name: "Captain Marvel"
}]

app.get('/', (req, res) => res.json(products))
app.listen(port, () => console.log(`Example app listening on port ${port}!`))
```

Install NPM dependencies:

```
npm install
```

Try it out by running `npm start` in the terminal. Go to a browser at `http://localhost:3000`. This should show a list of products.

Bring down the server with `CTRL+C`.

**Reviews service**

```
mkdir reviews
cd reviews
touch app.js
```

Now run:

```
npm init -y
```

This will create a `package.json` file.
In `package.json` add the following under `scripts`:

```json
"start": "node app.js"
```
Now your app is startable by typing `npm start`.

Add the following content to `app.js`:

```js
// reviews/app.js
const express = require('express')
const app = express()
const port = process.env.PORT || 3000

const reviews = [{
    id: 1,
    title: "Oh snap, what an ending",
    description: "wow wow wow..  Josh Brolin makes this movie",
    grade: 5,
    product: 1
  },
  {
    id: 2,
    name: "Captain America, the first avenger, so good",
    description: "WW2, good bad guy, what more do you want",
    grade: 5,
    product: 2
  },
  {
    id: 3,
    name: "Captain Marvel. Mar vel, get it? :)",
    description: "She must be the most powerful Avenger or? Definitely the fastest",
    grade: 5,
    product: 2
  }
]

app.get('/', (req, res) => res.json(reviews))
app.listen(port, () => console.log(`Example app listening on port ${port}!`))
```

Install NPM dependencies:

```
npm install
```

Try it out by running `npm start` in the terminal. Go to a browser at `http://localhost:3000`. This should show a list of products.


### Define a Dockerfile

We need to do this once for each service.

**Add Dockerfile to Products service**

Go to our `products` directory and create a file called `Dockerfile`. 

Give it the following content:

```
# Dockerfile

# from what OS
FROM node:10-alpine

## set workdir
WORKDIR /app

# set env variable
ENV PORT=3000

# install npm libraries
# doing this first makes docker take this step from cache on rebuild if dependencies are untouched,
# it saves much time in bigger projects
COPY package.json package-lock.json ./
RUN npm install

# copy source code files
COPY src/ .

# make the port exposed to the outside world
EXPOSE $PORT

# how to start the app, aka `npm start`
ENTRYPOINT ["npm", "start"]
```

**Add Dockerfile to Reviews service**

Go to our `reviews` directory and create a file called `Dockerfile`. Give it the following content:

```
# Dockerfile

# from what OS
FROM node:10-alpine

## set workdir
WORKDIR /app

# set env variable
ENV PORT=3000

# install npm libraries
# doing this first makes docker take this step from cache on rebuild if dependencies are untouched,
# it saves much time in bigger projects
COPY package.json package-lock.json ./
RUN npm install

# copy source code files
COPY src/ .

# make the port exposed to the outside world
EXPOSE $PORT

# how to start the app, aka `npm start`
ENTRYPOINT ["npm", "start"]
```

**Dockerize**

We've created a Dockerfile for each service. Our project structure should now look something like this:

```
products/
  src/
    app.js
  Dockerfile
  package.json
reviews/
  src/
    app.js
  Dockerfile
  package.json
```

Let's ensure we are at the root level and create a file called `docker-compose.yaml`. Give it the following content:

```yaml
version: '3.3'
services: 
  product-service:
    build:
      context: ./products
    ports:
      - "8000:3000"
    networks: 
      - microservices
  review-service:
    build:
      context: ./reviews
    ports:
      - "8001:3000"
    networks:
      - microservices
networks: 
  microservices:
```

What the above file says is:
For each service:
1. **run** the Dockerfile listed under `context`
2. **set up** a connection between host system port and container port `<host system port>:<container port>`
3. **put** each container in network `microservices`

Your project structure should now look like this:

```
docker-compose.yaml
products/
  src/
    app.js
  Dockerfile
  package.json
reviews/
  src/
    app.js
  Dockerfile
  package.json
```

If this IS the first time we just need to run the command:

```
docker-compose up -d
```

This will build an image of each service, then create and run a container.

If this is NOT the first time, you instead run the following command:

```
docker-compose build
docker-compose up -d
```
or the same in one line
```
docker-compose up --build -d
```

NOTE, we run `build` command to ensure that any changes to the Dockerfile is being rebuilt into a new image.

This should have started all services and you should be able to reach them on `http://localhost:8000` and `http://localhost:8001`. 

To take down the services type (no need for that yet):

```
docker-compose down
```

## Solution

[SOLUTION workshop part 3](https://github.com/softchris/serverless-graphql-microservices/tree/master/part3)
